{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "999121f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia-api\n",
      "  Downloading Wikipedia_API-0.6.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (from wikipedia-api) (2.32.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->wikipedia-api) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->wikipedia-api) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->wikipedia-api) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->wikipedia-api) (2.0.4)\n",
      "Installing collected packages: wikipedia-api\n",
      "Successfully installed wikipedia-api-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia-api pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94f6fd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17abf0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to wikipedia_infoboxes_filtered.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_infobox(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the infobox\n",
    "    infobox = soup.find('table', {'class': 'infobox vcard'})\n",
    "\n",
    "    # Extract the rows of the infobox\n",
    "    rows = infobox.find_all('tr') if infobox else []\n",
    "\n",
    "    infobox_data = {}\n",
    "    \n",
    "    # Only search for these specific fields\n",
    "    fields_of_interest = [\"Revenue\", \"CEO\", \"Market cap\", \"Profit margin\", \"Number of employees\"]\n",
    "    \n",
    "    for row in rows:\n",
    "        header = row.find('th') or row.find('td', {'class': 'infobox-label'})\n",
    "        if header:\n",
    "            header_text = header.text.strip()\n",
    "            data = row.find('td') or row.find('td', {'class': 'infobox-data'})\n",
    "            data_text = data.text.strip() if data else None\n",
    "\n",
    "            # Check if the header is one of the fields of interest\n",
    "            for field in fields_of_interest:\n",
    "                if field.lower() in header_text.lower():\n",
    "                    infobox_data[field] = data_text\n",
    "\n",
    "    return infobox_data\n",
    "\n",
    "# List of Wikipedia page URLs\n",
    "urls = [\n",
    "    \"https://en.wikipedia.org/wiki/Convergys\",\n",
    "\"https://en.wikipedia.org/wiki/Teleperformance\",\n",
    "\"https://en.wikipedia.org/wiki/Alorica\",\n",
    "\"https://en.wikipedia.org/wiki/TeleTech\",\n",
    "\"https://en.wikipedia.org/wiki/Xerox\",\n",
    "\"https://en.wikipedia.org/wiki/DXC_Technology\",\n",
    "\"https://en.wikipedia.org/wiki/NCO_Group\",\n",
    "\"https://en.wikipedia.org/wiki/Stericycle\",\n",
    "\"https://en.wikipedia.org/wiki/SYKES\",\n",
    "\"https://en.wikipedia.org/wiki/Genpact\",\n",
    "\"https://en.wikipedia.org/wiki/Aegis\",\n",
    "\"https://en.wikipedia.org/wiki/Sutherland_Global_Services\",\n",
    "\"https://en.wikipedia.org/wiki/Alida\",\n",
    "\"https://en.wikipedia.org/wiki/Clarabridge\",\n",
    "\"https://en.wikipedia.org/wiki/Conversica\",\n",
    "\"https://en.wikipedia.org/wiki/Five9\",\n",
    "\"https://en.wikipedia.org/wiki/Fonolo\",\n",
    "\"https://en.wikipedia.org/wiki/8x8\",\n",
    "\"https://en.wikipedia.org/wiki/Vocalcom\",\n",
    "\"https://en.wikipedia.org/wiki/Genesys\",\n",
    "\"https://en.wikipedia.org/wiki/Avaya\",\n",
    "\"https://en.wikipedia.org/wiki/Concentrix\",\n",
    "\"https://en.wikipedia.org/wiki/Conifer_Health_Solutions\",\n",
    "\"https://en.wikipedia.org/wiki/Wipro_Limited\",\n",
    "\"https://en.wikipedia.org/wiki/SYKES_Enterprises\",\n",
    "\"https://en.wikipedia.org/wiki/Sitel_Group\",\n",
    "\"https://en.wikipedia.org/wiki/Lionbridge\",\n",
    "\"https://en.wikipedia.org/wiki/Accenture\",\n",
    "\"https://en.wikipedia.org/wiki/Capgemini\",\n",
    "\"https://en.wikipedia.org/wiki/Infosys\",\n",
    "\"https://en.wikipedia.org/wiki/IBM\",\n",
    "\"https://en.wikipedia.org/wiki/TCS\",\n",
    "\"https://en.wikipedia.org/wiki/WNS_Global_Services\",\n",
    "\"https://en.wikipedia.org/wiki/Alight_Solutions\",\n",
    "\"https://en.wikipedia.org/wiki/SYSTIME_Technology\",\n",
    "\"https://en.wikipedia.org/wiki/EXL_Service\",\n",
    "\"https://en.wikipedia.org/wiki/WNS\",\n",
    "\"https://en.wikipedia.org/wiki/Wipro\",\n",
    "\"https://en.wikipedia.org/wiki/Tech_Mahindra\",\n",
    "\"https://en.wikipedia.org/wiki/Sutherland\",\n",
    "\"https://en.wikipedia.org/wiki/Firstsource\",\n",
    "\"https://en.wikipedia.org/wiki/HCL_Technologies\",\n",
    "\"https://en.wikipedia.org/wiki/Cartesian\",\n",
    "\"https://en.wikipedia.org/wiki/3i_Infotech\",\n",
    "\"https://en.wikipedia.org/wiki/HGS_Ltd.\",\n",
    "\"https://en.wikipedia.org/wiki/Indifi\",\n",
    "\"https://en.wikipedia.org/wiki/Zoukloans\",\n",
    "\"https://en.wikipedia.org/wiki/NASDAQ\"\n",
    "]\n",
    "\n",
    "# Collect infoboxes in a list\n",
    "infoboxes = []\n",
    "for url in urls:\n",
    "    infobox = fetch_infobox(url)\n",
    "    company_name = url.split(\"/wiki/\")[-1].replace(\"_\", \" \")\n",
    "    infobox['Company'] = company_name\n",
    "    infoboxes.append(infobox)\n",
    "    \n",
    "# Convert list of dictionaries to DataFrame\n",
    "df = pd.DataFrame(infoboxes)\n",
    "\n",
    "# Reorder columns so that 'Company' comes first\n",
    "columns_order = ['Company'] + [col for col in df.columns if col != 'Company']\n",
    "df = df[columns_order]\n",
    "\n",
    "# Save to Excel file\n",
    "df.to_excel('wikipedia_infoboxes_filtered.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to wikipedia_infoboxes_filtered.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973b7192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
